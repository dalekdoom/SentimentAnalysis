<html>
<head><meta http-equiv=Content-Type content="text/html; charset=UTF-8">
<style type="text/css">
<!--
span.cls_002{font-family:Arial,serif;font-size:7.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_002{font-family:Arial,serif;font-size:7.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_003{font-family:Arial,serif;font-size:24.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_003{font-family:Arial,serif;font-size:24.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_004{font-family:Arial,serif;font-size:11.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_004{font-family:Arial,serif;font-size:11.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_005{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_005{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_006{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_006{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_007{font-family:Arial,serif;font-size:8.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_007{font-family:Arial,serif;font-size:8.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
-->
</style>
<script type="text/javascript" src="f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_id_f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_files/wz_jsgraphics.js"></script>
</head>
<body>
<div style="position:absolute;left:50%;margin-left:-306px;top:0px;width:612px;height:792px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_id_f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_files/background1.jpg" width=612 height=792></div>
<div style="position:absolute;left:559.55px;top:24.25px" class="cls_002"><span class="cls_002">1</span></div>
<div style="position:absolute;left:103.40px;top:52.85px" class="cls_003"><span class="cls_003">Sentiment Analysis of Tweets to Airlines</span></div>
<div style="position:absolute;left:176.85px;top:89.11px" class="cls_004"><span class="cls_004">Rhys Evans (i6150369) and Parth Shrivastava (i6170757)</span></div>
<div style="position:absolute;left:58.93px;top:139.16px" class="cls_005"><span class="cls_005">Abstract—This report seeks to analyze the sentiment analysis</span></div>
<div style="position:absolute;left:400.35px;top:138.16px" class="cls_006"><span class="cls_006">III. C</span><span class="cls_007">LASSIFIERS</span></div>
<div style="position:absolute;left:48.96px;top:149.12px" class="cls_005"><span class="cls_005">of tweets to six different airline companies. The tweets will be</span></div>
<div style="position:absolute;left:321.94px;top:152.85px" class="cls_006"><span class="cls_006">We used a portion of the pre-classified data set to train our</span></div>
<div style="position:absolute;left:48.96px;top:159.08px" class="cls_005"><span class="cls_005">classified as positive, neutral, or negative using a training set, a</span></div>
<div style="position:absolute;left:311.98px;top:164.80px" class="cls_006"><span class="cls_006">approaches. SkLearn was used to implement these classifiers</span></div>
<div style="position:absolute;left:48.96px;top:169.05px" class="cls_005"><span class="cls_005">validation set, and a test set. Different type of classifiers will be</span></div>
<div style="position:absolute;left:48.96px;top:179.01px" class="cls_005"><span class="cls_005">used to conduct tests on sentiment accuracy.</span></div>
<div style="position:absolute;left:311.98px;top:176.76px" class="cls_006"><span class="cls_006">[2].</span></div>
<div style="position:absolute;left:311.98px;top:197.84px" class="cls_006"><span class="cls_006">A. Logistic Regression</span></div>
<div style="position:absolute;left:135.62px;top:206.93px" class="cls_006"><span class="cls_006">I. I</span><span class="cls_007">NTRODUCTION</span></div>
<div style="position:absolute;left:321.94px;top:212.52px" class="cls_006"><span class="cls_006">This works by using a linear weighted sum, by assigning</span></div>
<div style="position:absolute;left:58.93px;top:221.89px" class="cls_006"><span class="cls_006">We want to conduct sentiment classification of tweets to</span></div>
<div style="position:absolute;left:311.98px;top:224.48px" class="cls_006"><span class="cls_006">different  weights  to  different  words  in  the  tweets</span></div>
<div style="position:absolute;left:534.26px;top:224.48px" class="cls_006"><span class="cls_006">(higher</span></div>
<div style="position:absolute;left:48.96px;top:233.85px" class="cls_006"><span class="cls_006">airlines  to  determine  whether  they  are  positive</span></div>
<div style="position:absolute;left:260.41px;top:233.85px" class="cls_006"><span class="cls_006">(reviews),</span></div>
<div style="position:absolute;left:311.98px;top:236.43px" class="cls_006"><span class="cls_006">weights for words which have a higher chance of affecting</span></div>
<div style="position:absolute;left:48.96px;top:245.80px" class="cls_006"><span class="cls_006">negative (complaints), or neutral (statements). This problem is</span></div>
<div style="position:absolute;left:311.98px;top:248.39px" class="cls_006"><span class="cls_006">the resulting sentiment).</span></div>
<div style="position:absolute;left:48.96px;top:257.76px" class="cls_006"><span class="cls_006">interesting from a business perspective because it is useful to</span></div>
<div style="position:absolute;left:48.96px;top:269.71px" class="cls_006"><span class="cls_006">know which airline has better reviews. Using natural language</span></div>
<div style="position:absolute;left:311.98px;top:269.47px" class="cls_006"><span class="cls_006">B. Gaussian Naïve Bayes</span></div>
<div style="position:absolute;left:48.96px;top:281.67px" class="cls_006"><span class="cls_006">processing allows businesses to analyze public opinion through</span></div>
<div style="position:absolute;left:321.94px;top:284.16px" class="cls_006"><span class="cls_006">We can use Bayes classifiers with the presence of n-grams</span></div>
<div style="position:absolute;left:48.96px;top:293.62px" class="cls_006"><span class="cls_006">tweets without having to conduct formal surveys. They can</span></div>
<div style="position:absolute;left:311.98px;top:296.11px" class="cls_006"><span class="cls_006">and part-of-speech distribution information, as done in Twitter</span></div>
<div style="position:absolute;left:48.96px;top:305.58px" class="cls_006"><span class="cls_006">then use this information to drive business decisions because</span></div>
<div style="position:absolute;left:311.98px;top:308.07px" class="cls_006"><span class="cls_006">as  a  Corpus  for  Sentiment  Analysis  and  Opinion  Mining</span></div>
<div style="position:absolute;left:48.96px;top:317.53px" class="cls_006"><span class="cls_006">they will have an insight into what customers think of them</span></div>
<div style="position:absolute;left:311.98px;top:319.97px" class="cls_006"><span class="cls_006">from Université de Paris-Sud [3]. It basically makes use of</span></div>
<div style="position:absolute;left:48.96px;top:329.49px" class="cls_006"><span class="cls_006">and into what customers think of their competition.</span></div>
<div style="position:absolute;left:311.98px;top:331.98px" class="cls_006"><span class="cls_006">the Bayes Theorem (for a Gaussian distribution) and finds</span></div>
<div style="position:absolute;left:311.98px;top:343.93px" class="cls_006"><span class="cls_006">probability of a sentiment given the data(tweet).</span></div>
<div style="position:absolute;left:48.96px;top:355.11px" class="cls_006"><span class="cls_006">A. Dataset</span></div>
<div style="position:absolute;left:311.98px;top:365.02px" class="cls_006"><span class="cls_006">C. Random Forest Method</span></div>
<div style="position:absolute;left:58.93px;top:370.07px" class="cls_006"><span class="cls_006">The dataset used contains tweets from February 16th to</span></div>
<div style="position:absolute;left:48.96px;top:382.03px" class="cls_006"><span class="cls_006">February 24th 2015. The tweets were directed at six major</span></div>
<div style="position:absolute;left:321.94px;top:379.70px" class="cls_006"><span class="cls_006">Another method that has been used in the past is the random</span></div>
<div style="position:absolute;left:48.96px;top:393.98px" class="cls_006"><span class="cls_006">airlines in the United States. The tweets are classified as</span></div>
<div style="position:absolute;left:311.98px;top:391.66px" class="cls_006"><span class="cls_006">forest method. This classifier was implemented in Sentiment</span></div>
<div style="position:absolute;left:48.96px;top:405.94px" class="cls_006"><span class="cls_006">either  positive,  negative,  or  neutral.  The  dataset  is  called</span></div>
<div style="position:absolute;left:311.98px;top:403.61px" class="cls_006"><span class="cls_006">analysis using product review data the Journal of Big Data [4].</span></div>
<div style="position:absolute;left:48.96px;top:417.89px" class="cls_006"><span class="cls_006">Airline Twitter sentiment and is taken from Figure Eight Inc.</span></div>
<div style="position:absolute;left:311.98px;top:415.57px" class="cls_006"><span class="cls_006">In simple terms, the ”random forest [classifier] builds multiple</span></div>
<div style="position:absolute;left:48.96px;top:429.85px" class="cls_006"><span class="cls_006">[1]. According to the source, Twitter data was scraped from</span></div>
<div style="position:absolute;left:311.98px;top:427.52px" class="cls_006"><span class="cls_006">decision trees and merges them together to get a more accurate</span></div>
<div style="position:absolute;left:48.96px;top:441.80px" class="cls_006"><span class="cls_006">February of 2015 and contributors were asked to first classify</span></div>
<div style="position:absolute;left:311.98px;top:439.48px" class="cls_006"><span class="cls_006">and stable prediction” [5]. It is an ensemble of Decision Trees</span></div>
<div style="position:absolute;left:48.96px;top:453.76px" class="cls_006"><span class="cls_006">positive, negative, and neutral tweets, followed by categorizing</span></div>
<div style="position:absolute;left:311.98px;top:451.43px" class="cls_006"><span class="cls_006">that have been trained with the Bootstrap Aggregation method</span></div>
<div style="position:absolute;left:48.96px;top:465.71px" class="cls_006"><span class="cls_006">negative reasons (such as late flight or rude service). However,</span></div>
<div style="position:absolute;left:311.98px;top:463.39px" class="cls_006"><span class="cls_006">[6].</span></div>
<div style="position:absolute;left:48.96px;top:477.67px" class="cls_006"><span class="cls_006">we cannot apply this approach because we do not have the</span></div>
<div style="position:absolute;left:415.09px;top:482.23px" class="cls_006"><span class="cls_006">IV. T</span><span class="cls_007">ESTS</span></div>
<div style="position:absolute;left:48.96px;top:489.62px" class="cls_006"><span class="cls_006">means to survey contributors and ask them to classify the</span></div>
<div style="position:absolute;left:321.94px;top:496.91px" class="cls_006"><span class="cls_006">We compared the accuracies of different classifiers and then</span></div>
<div style="position:absolute;left:48.96px;top:501.58px" class="cls_006"><span class="cls_006">sentiment of 14640 tweets.</span></div>
<div style="position:absolute;left:311.98px;top:508.87px" class="cls_006"><span class="cls_006">conducted significance tests on those accuracies to determine</span></div>
<div style="position:absolute;left:311.98px;top:520.83px" class="cls_006"><span class="cls_006">whether different approaches were more statistically signifi-</span></div>
<div style="position:absolute;left:48.96px;top:527.20px" class="cls_006"><span class="cls_006">B. Research Question and Hypothesis</span></div>
<div style="position:absolute;left:311.98px;top:532.78px" class="cls_006"><span class="cls_006">cant than other approaches. These statistical tests are useful</span></div>
<div style="position:absolute;left:58.93px;top:542.16px" class="cls_006"><span class="cls_006">We want to determine which classifier yields the high-</span></div>
<div style="position:absolute;left:311.98px;top:544.74px" class="cls_006"><span class="cls_006">because they can tell us if our model prediction is sufficiently</span></div>
<div style="position:absolute;left:48.96px;top:554.12px" class="cls_006"><span class="cls_006">est accuracy, precision, and recall. We believe that Logistic</span></div>
<div style="position:absolute;left:311.98px;top:556.69px" class="cls_006"><span class="cls_006">good.</span></div>
<div style="position:absolute;left:48.96px;top:566.07px" class="cls_006"><span class="cls_006">Regression  will  be  the  best  classifier  because  it  gives  a</span></div>
<div style="position:absolute;left:48.96px;top:578.03px" class="cls_006"><span class="cls_006">higher weight for words with a higher chance of affecting</span></div>
<div style="position:absolute;left:311.98px;top:577.78px" class="cls_006"><span class="cls_006">A. Setup</span></div>
<div style="position:absolute;left:48.96px;top:589.98px" class="cls_006"><span class="cls_006">the sentiment. This should improve it’s accuracy because in</span></div>
<div style="position:absolute;left:321.94px;top:592.46px" class="cls_006"><span class="cls_006">The training set and test set were split up in such a way that</span></div>
<div style="position:absolute;left:48.96px;top:601.94px" class="cls_006"><span class="cls_006">tweets and reviews, the words are not independent. They are</span></div>
<div style="position:absolute;left:311.98px;top:604.41px" class="cls_006"><span class="cls_006">the latest tweets were used as test set, and all the prior tweets</span></div>
<div style="position:absolute;left:48.96px;top:613.89px" class="cls_006"><span class="cls_006">all dependent on each other to compose a coherent thought.</span></div>
<div style="position:absolute;left:311.98px;top:616.37px" class="cls_006"><span class="cls_006">as training, so that this way we use our models to ”predict”</span></div>
<div style="position:absolute;left:48.96px;top:625.85px" class="cls_006"><span class="cls_006">With logistic regression, this is taken into account.</span></div>
<div style="position:absolute;left:311.98px;top:628.32px" class="cls_006"><span class="cls_006">future tweets based on past ones rather than the other way.</span></div>
<div style="position:absolute;left:311.98px;top:640.28px" class="cls_006"><span class="cls_006">Tweets from February 16th to February 22nd were used as</span></div>
<div style="position:absolute;left:65.00px;top:649.22px" class="cls_006"><span class="cls_006">II. A</span><span class="cls_007">PPROACH</span><span class="cls_006"> (B</span><span class="cls_007">AG OF</span><span class="cls_006"> W</span><span class="cls_007">ORDS</span><span class="cls_006"> R</span><span class="cls_007">EPRESENTATION</span><span class="cls_006">)</span></div>
<div style="position:absolute;left:311.98px;top:652.23px" class="cls_006"><span class="cls_006">training data and tweets from February 23rd and 24th were</span></div>
<div style="position:absolute;left:58.93px;top:664.19px" class="cls_006"><span class="cls_006">We approached this problem with Bag of Words. In BOW,</span></div>
<div style="position:absolute;left:311.98px;top:664.19px" class="cls_006"><span class="cls_006">used to test. The tweets used in the test remained constant</span></div>
<div style="position:absolute;left:48.96px;top:676.14px" class="cls_006"><span class="cls_006">the tweets are first cleaned by removing stop-words, which</span></div>
<div style="position:absolute;left:311.98px;top:676.15px" class="cls_006"><span class="cls_006">throughout our tests. The parameters we varied in our exper-</span></div>
<div style="position:absolute;left:48.96px;top:688.10px" class="cls_006"><span class="cls_006">don’t have a significant impact on the resulting sentiment of</span></div>
<div style="position:absolute;left:311.98px;top:688.10px" class="cls_006"><span class="cls_006">iments were test-size (which tells us how much proportion</span></div>
<div style="position:absolute;left:48.96px;top:700.06px" class="cls_006"><span class="cls_006">the tweet. The clean tweets are then stored in a vectorized</span></div>
<div style="position:absolute;left:311.98px;top:700.06px" class="cls_006"><span class="cls_006">of data will be split for testing+validation vs training, so</span></div>
<div style="position:absolute;left:48.96px;top:712.01px" class="cls_006"><span class="cls_006">bag of words form. They are then sorted by sentiment by</span></div>
<div style="position:absolute;left:311.98px;top:712.01px" class="cls_006"><span class="cls_006">the smaller the value, higher the comparative training) and</span></div>
<div style="position:absolute;left:48.96px;top:723.97px" class="cls_006"><span class="cls_006">quantifying the tweets: if positive then 1, if negative then -1,</span></div>
<div style="position:absolute;left:311.98px;top:723.97px" class="cls_006"><span class="cls_006">random-state (which randomizes different portions of the data</span></div>
<div style="position:absolute;left:48.96px;top:735.92px" class="cls_006"><span class="cls_006">if neutral then 0.</span></div>
<div style="position:absolute;left:311.98px;top:735.92px" class="cls_006"><span class="cls_006">for training/validation).</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-306px;top:802px;width:612px;height:792px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_id_f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_files/background2.jpg" width=612 height=792></div>
<div style="position:absolute;left:559.55px;top:24.25px" class="cls_002"><span class="cls_002">2</span></div>
<div style="position:absolute;left:92.64px;top:54.48px" class="cls_006"><span class="cls_006">V. E</span><span class="cls_007">XPERIMENTAL</span><span class="cls_006"> R</span><span class="cls_007">ESULT</span><span class="cls_006"> A</span><span class="cls_007">NALYSIS</span></div>
<div style="position:absolute;left:58.93px;top:69.40px" class="cls_006"><span class="cls_006">In figures 1, 2, and 3 (which randomize different parts of the</span></div>
<div style="position:absolute;left:48.96px;top:81.35px" class="cls_006"><span class="cls_006">data as training/validation), Logistic Regression consistently</span></div>
<div style="position:absolute;left:48.96px;top:93.26px" class="cls_006"><span class="cls_006">outperforms Random Forest and Gaussian Naïve Bayes, with</span></div>
<div style="position:absolute;left:48.96px;top:105.21px" class="cls_006"><span class="cls_006">Gaussian Naïve Bayes being the worst of all 3. This is most</span></div>
<div style="position:absolute;left:48.96px;top:117.17px" class="cls_006"><span class="cls_006">likely due to the fact that Gaussian Naïve Bayes assumes that</span></div>
<div style="position:absolute;left:48.96px;top:129.17px" class="cls_006"><span class="cls_006">each feature (word) in a tweet is independent, when in reality,</span></div>
<div style="position:absolute;left:48.96px;top:141.13px" class="cls_006"><span class="cls_006">this is not always the case. This big assumption gives it a much</span></div>
<div style="position:absolute;left:48.96px;top:153.08px" class="cls_006"><span class="cls_006">lower accuracy. Logistic regression outperforms the other 2</span></div>
<div style="position:absolute;left:48.96px;top:165.04px" class="cls_006"><span class="cls_006">classifiers because it uses a linear combination of the features</span></div>
<div style="position:absolute;left:48.96px;top:176.99px" class="cls_006"><span class="cls_006">(words) by assigning higher weights to words which have a</span></div>
<div style="position:absolute;left:48.96px;top:188.95px" class="cls_006"><span class="cls_006">higher (maximum) likelihood of affecting a sentiment. It also</span></div>
<div style="position:absolute;left:48.96px;top:200.90px" class="cls_006"><span class="cls_006">performs slightly better than Random Forest because Random</span></div>
<div style="position:absolute;left:48.96px;top:212.86px" class="cls_006"><span class="cls_006">Forest makes use of decision trees, which, without pruning,</span></div>
<div style="position:absolute;left:48.96px;top:224.81px" class="cls_006"><span class="cls_006">make it more prone to overfitting than Logistic Regression as</span></div>
<div style="position:absolute;left:333.81px;top:229.55px" class="cls_005"><span class="cls_005">Figure 3: Classifier performances with random state = 3</span></div>
<div style="position:absolute;left:48.96px;top:236.77px" class="cls_006"><span class="cls_006">it can scale up to be very complex. Random Forest decision</span></div>
<div style="position:absolute;left:48.96px;top:248.72px" class="cls_006"><span class="cls_006">trees would work much better if the task was a high multi-</span></div>
<div style="position:absolute;left:48.96px;top:260.68px" class="cls_006"><span class="cls_006">classification with many output class types/labels (in our case</span></div>
<div style="position:absolute;left:311.98px;top:269.33px" class="cls_006"><span class="cls_006">which is not good training for real-world test data. On the</span></div>
<div style="position:absolute;left:48.96px;top:272.63px" class="cls_006"><span class="cls_006">it is trinary, i.e, -1,0,1).</span></div>
<div style="position:absolute;left:311.98px;top:281.24px" class="cls_006"><span class="cls_006">other hand, the more we overfit, the better Gaussian Naïve</span></div>
<div style="position:absolute;left:311.98px;top:293.24px" class="cls_006"><span class="cls_006">Bayes performs. This is because with a larger training (vs</span></div>
<div style="position:absolute;left:311.98px;top:305.20px" class="cls_006"><span class="cls_006">validation) set, there is a higher chance of coming across</span></div>
<div style="position:absolute;left:311.98px;top:317.15px" class="cls_006"><span class="cls_006">features</span></div>
<div style="position:absolute;left:348.92px;top:317.15px" class="cls_006"><span class="cls_006">(words) with a higher dependence on each other,</span></div>
<div style="position:absolute;left:311.98px;top:329.11px" class="cls_006"><span class="cls_006">which would be considered independent by this classifier. In</span></div>
<div style="position:absolute;left:311.98px;top:341.01px" class="cls_006"><span class="cls_006">other words, Gaussian Naïve Bayes gets ’exposed’ for its</span></div>
<div style="position:absolute;left:311.98px;top:352.97px" class="cls_006"><span class="cls_006">naïvety of assuming feature independence the more we train.</span></div>
<div style="position:absolute;left:311.98px;top:364.97px" class="cls_006"><span class="cls_006">In general it works better for smaller datasets as it is less prone</span></div>
<div style="position:absolute;left:311.98px;top:376.93px" class="cls_006"><span class="cls_006">to overfitting.</span></div>
<div style="position:absolute;left:321.94px;top:391.62px" class="cls_006"><span class="cls_006">We also conducted P/R/F1 tests for further evaluation. Our</span></div>
<div style="position:absolute;left:311.98px;top:403.58px" class="cls_006"><span class="cls_006">precision, recall, and F1 tests all supported our previous find-</span></div>
<div style="position:absolute;left:311.98px;top:415.53px" class="cls_006"><span class="cls_006">ings that Logistic Regression was the most accurate classifier</span></div>
<div style="position:absolute;left:311.98px;top:427.44px" class="cls_006"><span class="cls_006">and that Gaussian Naïve Bayes was the least accurate. For</span></div>
<div style="position:absolute;left:311.98px;top:439.44px" class="cls_006"><span class="cls_006">these tests, we used the metrics package provided through</span></div>
<div style="position:absolute;left:311.98px;top:451.40px" class="cls_006"><span class="cls_006">SKLearn [2]. Our recall tests determined the percentage of</span></div>
<div style="position:absolute;left:311.98px;top:463.35px" class="cls_006"><span class="cls_006">correct items that were selected, our precision tests determined</span></div>
<div style="position:absolute;left:70.79px;top:471.36px" class="cls_005"><span class="cls_005">Figure 1: Classifier performances with random state = 1</span></div>
<div style="position:absolute;left:311.98px;top:475.31px" class="cls_006"><span class="cls_006">the percentage of selected items that were correct, and our F1</span></div>
<div style="position:absolute;left:311.98px;top:487.26px" class="cls_006"><span class="cls_006">test assessed the P/R tradeoff. We were unable to compute</span></div>
<div style="position:absolute;left:311.98px;top:499.22px" class="cls_006"><span class="cls_006">the Area Under the Receiver Operating Characteristic curve</span></div>
<div style="position:absolute;left:311.98px;top:511.17px" class="cls_006"><span class="cls_006">(AUROC) from prediction scores because our dataset is not</span></div>
<div style="position:absolute;left:311.98px;top:523.13px" class="cls_006"><span class="cls_006">binary and AUROC is restricted to the binary classification</span></div>
<div style="position:absolute;left:311.98px;top:535.08px" class="cls_006"><span class="cls_006">task.</span></div>
<div style="position:absolute;left:70.79px;top:679.03px" class="cls_005"><span class="cls_005">Figure 2: Classifier performances with random state = 2</span></div>
<div style="position:absolute;left:58.93px;top:700.05px" class="cls_006"><span class="cls_006">Another curious thing to note is that the more we train</span></div>
<div style="position:absolute;left:325.82px;top:709.24px" class="cls_005"><span class="cls_005">Figure 4: Precision performance with fixes test size (0.1) and</span></div>
<div style="position:absolute;left:48.96px;top:712.01px" class="cls_006"><span class="cls_006">vs validate (i.e, the less we overfit), the better both Logistic</span></div>
<div style="position:absolute;left:408.65px;top:719.20px" class="cls_005"><span class="cls_005">random state (1)</span></div>
<div style="position:absolute;left:48.96px;top:723.97px" class="cls_006"><span class="cls_006">Regression and Random Forest work. This is because more</span></div>
<div style="position:absolute;left:48.96px;top:735.92px" class="cls_006"><span class="cls_006">overfitting makes it more specific to a certain kind of data,</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-306px;top:1604px;width:612px;height:792px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_id_f9f39b9a-80fc-11e9-9d71-0cc47a792c0a_files/background3.jpg" width=612 height=792></div>
<div style="position:absolute;left:559.55px;top:24.25px" class="cls_002"><span class="cls_002">3</span></div>
<div style="position:absolute;left:409.61px;top:54.48px" class="cls_006"><span class="cls_006">R</span><span class="cls_007">EFERENCES</span></div>
<div style="position:absolute;left:311.98px;top:71.32px" class="cls_007"><span class="cls_007">[1]</span></div>
<div style="position:absolute;left:326.25px;top:71.32px" class="cls_007"><span class="cls_007">“Data  for  everyone,”</span></div>
<div style="position:absolute;left:401.69px;top:71.32px" class="cls_007"><span class="cls_007">(Accessed  on  05/27/2019).</span></div>
<div style="position:absolute;left:497.06px;top:71.32px" class="cls_007"><span class="cls_007">[Online].  Available:</span></div>
<div style="position:absolute;left:326.25px;top:80.28px" class="cls_007"><span class="cls_007"> </span><A HREF="https://www.figure-eight.com/data-for-everyone/">https://www.figure-eight.com/data-for-everyone/</A> </div>
<div style="position:absolute;left:311.98px;top:89.25px" class="cls_007"><span class="cls_007">[2]  F.  Pedregosa,  G.  Varoquaux,  A.  Gramfort,  V.  Michel,  B.  Thirion,</span></div>
<div style="position:absolute;left:326.25px;top:98.22px" class="cls_007"><span class="cls_007">O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Van-</span></div>
<div style="position:absolute;left:326.25px;top:107.18px" class="cls_007"><span class="cls_007">derplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-</span></div>
<div style="position:absolute;left:326.25px;top:116.15px" class="cls_007"><span class="cls_007">esnay, “Scikit-learn: Machine Learning in Python ,” Journal of Machine</span></div>
<div style="position:absolute;left:326.25px;top:125.12px" class="cls_007"><span class="cls_007">Learning Research, vol. 12, pp. 2825-2830, 2011.</span></div>
<div style="position:absolute;left:311.98px;top:134.08px" class="cls_007"><span class="cls_007">[3]  A. Pak and P. Paroubek, “Twitter as a corpus for sentiment analysis and</span></div>
<div style="position:absolute;left:326.25px;top:143.05px" class="cls_007"><span class="cls_007">opinion mining.” in LREc, vol. 10, no. 2010, 2010, pp. 1320-1326.</span></div>
<div style="position:absolute;left:311.98px;top:152.02px" class="cls_007"><span class="cls_007">[4]  X. Fang and J. Zhan, “Sentiment analysis using product review data,”</span></div>
<div style="position:absolute;left:326.25px;top:160.98px" class="cls_007"><span class="cls_007">Journal of Big Data, vol. 2, no. 1, p. 5, 2015.</span></div>
<div style="position:absolute;left:311.98px;top:169.95px" class="cls_007"><span class="cls_007">[5]</span></div>
<div style="position:absolute;left:326.25px;top:169.95px" class="cls_007"><span class="cls_007">“The  random  forest  algorithm   towards  data  science,”</span></div>
<div style="position:absolute;left:530.29px;top:169.95px" class="cls_007"><span class="cls_007">(Accessed</span></div>
<div style="position:absolute;left:326.25px;top:178.91px" class="cls_007"><span class="cls_007">on</span></div>
<div style="position:absolute;left:340.39px;top:178.91px" class="cls_007"><span class="cls_007">05/27/2019).</span></div>
<div style="position:absolute;left:387.52px;top:178.91px" class="cls_007"><span class="cls_007">[Online].  Available:  </span><A HREF="https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd">https://towardsdatascience.com/</A> </div>
<div style="position:absolute;left:326.25px;top:187.88px" class="cls_007"><span class="cls_007"> </span><A HREF="https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd">the-random-forest-algorithm-d457d499ffcd</A> </div>
<div style="position:absolute;left:311.98px;top:196.85px" class="cls_007"><span class="cls_007">[6]  J.  Brownlee,</span></div>
<div style="position:absolute;left:374.34px;top:196.85px" class="cls_007"><span class="cls_007">“Bagging  and  random  forest  ensemble  algorithms  for</span></div>
<div style="position:absolute;left:52.77px;top:199.10px" class="cls_005"><span class="cls_005">Figure 5: Recall performance with fixes test size (0.1) and random</span></div>
<div style="position:absolute;left:326.25px;top:205.81px" class="cls_007"><span class="cls_007">machine learning,” April 2016.</span></div>
<div style="position:absolute;left:160.90px;top:209.06px" class="cls_005"><span class="cls_005">state (1)</span></div>
<div style="position:absolute;left:49.71px;top:379.96px" class="cls_005"><span class="cls_005">Figure 6: F1 performance with fixes test size (0.1) and random state</span></div>
<div style="position:absolute;left:170.68px;top:389.92px" class="cls_005"><span class="cls_005">(1)</span></div>
<div style="position:absolute;left:93.70px;top:424.57px" class="cls_006"><span class="cls_006">VI. I</span><span class="cls_007">NTERESTING</span><span class="cls_006"> T</span><span class="cls_007">ESTS TO LOOK</span><span class="cls_006"> A</span><span class="cls_007">T</span></div>
<div style="position:absolute;left:58.93px;top:444.54px" class="cls_006"><span class="cls_006">One interesting question to research could be how a certain</span></div>
<div style="position:absolute;left:48.96px;top:456.49px" class="cls_006"><span class="cls_006">airline company correlates to a certain sentiment. However,</span></div>
<div style="position:absolute;left:48.96px;top:468.45px" class="cls_006"><span class="cls_006">it would be necessary to keep in mind that this could have</span></div>
<div style="position:absolute;left:48.96px;top:480.40px" class="cls_006"><span class="cls_006">biases based on the context of the airline companies over</span></div>
<div style="position:absolute;left:48.96px;top:492.36px" class="cls_006"><span class="cls_006">the internet</span></div>
<div style="position:absolute;left:102.05px;top:492.36px" class="cls_006"><span class="cls_006">(if they are used in a positive/negative/neutral</span></div>
<div style="position:absolute;left:48.96px;top:504.31px" class="cls_006"><span class="cls_006">reference). Another research possibility would be to look at</span></div>
<div style="position:absolute;left:48.96px;top:516.27px" class="cls_006"><span class="cls_006">significance tests to determine how significantly better a given</span></div>
<div style="position:absolute;left:48.96px;top:528.22px" class="cls_006"><span class="cls_006">classifier performs etc.</span></div>
<div style="position:absolute;left:131.83px;top:560.53px" class="cls_006"><span class="cls_006">VII. C</span><span class="cls_007">ONCLUSIONS</span></div>
<div style="position:absolute;left:58.93px;top:580.50px" class="cls_006"><span class="cls_006">Many different factors affect which classifier is superior. It</span></div>
<div style="position:absolute;left:48.96px;top:592.46px" class="cls_006"><span class="cls_006">depends on factors such as the task at hand, how dependent</span></div>
<div style="position:absolute;left:48.96px;top:604.41px" class="cls_006"><span class="cls_006">the dataset is, how large it is, how much of it classified, and</span></div>
<div style="position:absolute;left:48.96px;top:616.37px" class="cls_006"><span class="cls_006">what type of classification task it is. Airline sentiment analysis</span></div>
<div style="position:absolute;left:48.96px;top:628.32px" class="cls_006"><span class="cls_006">is an interesting task because airline companies are constantly</span></div>
<div style="position:absolute;left:48.96px;top:640.28px" class="cls_006"><span class="cls_006">look to better their selves to compete with fellow airlines.</span></div>
<div style="position:absolute;left:48.96px;top:652.23px" class="cls_006"><span class="cls_006">This same competitive business paradigm can also be applied</span></div>
<div style="position:absolute;left:48.96px;top:664.19px" class="cls_006"><span class="cls_006">to many different fields including hotel ratings, agency ratings,</span></div>
<div style="position:absolute;left:48.96px;top:676.14px" class="cls_006"><span class="cls_006">movie rating, and many more. There are countless situations</span></div>
<div style="position:absolute;left:48.96px;top:688.10px" class="cls_006"><span class="cls_006">where such data is provided in the form of text (not numbers),</span></div>
<div style="position:absolute;left:48.96px;top:700.06px" class="cls_006"><span class="cls_006">and Natural Language Processing combined with Machine</span></div>
<div style="position:absolute;left:48.96px;top:712.01px" class="cls_006"><span class="cls_006">Learning is able to give an insight into what’s working well</span></div>
<div style="position:absolute;left:48.96px;top:723.97px" class="cls_006"><span class="cls_006">and what isn’t, and to find key patterns to give an edge to</span></div>
<div style="position:absolute;left:48.96px;top:735.92px" class="cls_006"><span class="cls_006">maximize performance.</span></div>
</div>

</body>
</html>
